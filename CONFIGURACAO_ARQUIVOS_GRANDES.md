# ðŸ“ SoluÃ§Ãµes para Arquivos Grandes no GitHub

## ðŸš¨ **Problema:**
- GitHub limita arquivos a **100MB** cada
- Limite total do repositÃ³rio: **1GB**
- Arquivos `.txt` de extraÃ§Ã£o sÃ£o maiores que isso

## ðŸ’¡ **SoluÃ§Ãµes DisponÃ­veis:**

### **OpÃ§Ã£o 1: Git LFS (Recomendada)**
```bash
# Instalar Git LFS
git lfs install

# Configurar para arquivos .txt
git lfs track "*.txt"
git add .gitattributes
git commit -m "Configurar Git LFS para arquivos .txt"

# Adicionar arquivos grandes
git add KE5Z/
git commit -m "Adicionar arquivos de dados com LFS"
git push
```

### **OpÃ§Ã£o 2: CompressÃ£o dos Arquivos**
```python
# Script para comprimir arquivos antes do upload
import gzip
import shutil

def comprimir_arquivos():
    for arquivo in os.listdir("KE5Z"):
        if arquivo.endswith('.txt'):
            with open(f"KE5Z/{arquivo}", 'rb') as f_in:
                with gzip.open(f"KE5Z/{arquivo}.gz", 'wb') as f_out:
                    shutil.copyfileobj(f_in, f_out)
```

### **OpÃ§Ã£o 3: DivisÃ£o dos Arquivos**
```python
# Script para dividir arquivos grandes
def dividir_arquivo(arquivo, tamanho_max=50*1024*1024):  # 50MB
    with open(arquivo, 'r') as f:
        conteudo = f.read()
    
    partes = len(conteudo) // tamanho_max + 1
    for i in range(partes):
        inicio = i * tamanho_max
        fim = (i + 1) * tamanho_max
        with open(f"{arquivo}.part{i+1}", 'w') as f:
            f.write(conteudo[inicio:fim])
```

### **OpÃ§Ã£o 4: Upload Manual via Streamlit (Mais Simples)**
Criar interface no Streamlit para upload dos arquivos.

## ðŸŽ¯ **SoluÃ§Ã£o Implementada: Upload via Streamlit**

âœ… **Sistema de Upload Direto no Dashboard**

### **Como Funciona:**
1. **Acesse o dashboard** no Streamlit Cloud
2. **FaÃ§a login** como administrador
3. **Na barra lateral**, vÃ¡ em "ðŸ”„ Atualizar Dados"
4. **Selecione os arquivos .txt** usando o uploader
5. **Clique em "ðŸ“Š Processar Arquivos Upload"**
6. **Sistema processa** e atualiza os dados automaticamente

### **Vantagens:**
- âœ… **Sem limite de tamanho** (processamento em memÃ³ria)
- âœ… **NÃ£o precisa do GitHub** para os dados
- âœ… **Interface simples** e intuitiva
- âœ… **Processamento automÃ¡tico** dos arquivos
- âœ… **Funciona para qualquer usuÃ¡rio**

### **Fluxo Completo:**
1. **Upload** â†’ Seleciona arquivos .txt
2. **Processamento** â†’ Aplica filtros e limpeza
3. **GeraÃ§Ã£o** â†’ Cria arquivo KE5Z.parquet
4. **AtualizaÃ§Ã£o** â†’ Dashboard mostra novos dados
5. **Download** â†’ UsuÃ¡rios podem baixar os dados processados

### **Requisitos:**
- âœ… Apenas arquivos .txt
- âœ… Formato padrÃ£o (separado por tab, 9 linhas de cabeÃ§alho)
- âœ… Encoding Latin1
- âœ… Coluna 'Ano' para filtros

## ðŸš¨ **Nova LimitaÃ§Ã£o Descoberta:**
- Streamlit Cloud limita uploads a **200MB por arquivo**
- SoluÃ§Ã£o: DivisÃ£o de arquivos grandes

## ðŸ”§ **SoluÃ§Ãµes Implementadas:**

### **OpÃ§Ã£o 1: Upload Direto (â‰¤200MB)**
- âœ… **Arquivos atÃ© 200MB** - upload direto
- âœ… **Interface simples** - drag & drop
- âœ… **Processamento automÃ¡tico**

### **OpÃ§Ã£o 2: DivisÃ£o de Arquivos (>200MB)**
- âœ… **Script local** - `dividir_arquivos.py`
- âœ… **DivisÃ£o automÃ¡tica** em partes de 150MB
- âœ… **Preserva cabeÃ§alho** em cada parte
- âœ… **Upload das partes** no Streamlit

## ðŸ“‹ **Como Usar:**

### **Para Arquivos â‰¤200MB:**
1. Acesse o dashboard
2. Use "ðŸ“ Upload de Arquivos"
3. Selecione os arquivos .txt
4. Clique em "ðŸ“Š Processar Arquivos Upload"

### **Para Arquivos >200MB:**
1. **Use o script local:**
   ```bash
   python dividir_arquivos.py "caminho/arquivo.txt" 150
   ```
2. **Upload das partes** usando a opÃ§Ã£o de upload
3. **Processamento automÃ¡tico** de todas as partes

**ðŸŽ‰ Problema resolvido! Agora vocÃª pode usar arquivos de qualquer tamanho.**
